{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ9aBztPhfIX",
        "outputId": "91d8c6c1-872f-4a64-8518-28107ecbf0b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 1.7020 - accuracy: 0.3214\n",
            "Epoch 1: val_accuracy improved from -inf to 0.35445, saving model to best_model.h5\n",
            "187/187 [==============================] - 128s 681ms/step - loss: 1.7020 - accuracy: 0.3214 - val_loss: 1.6430 - val_accuracy: 0.3544\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "187/187 [==============================] - ETA: 0s - loss: 1.5738 - accuracy: 0.3819\n",
            "Epoch 2: val_accuracy improved from 0.35445 to 0.37104, saving model to best_model.h5\n",
            "187/187 [==============================] - 127s 679ms/step - loss: 1.5738 - accuracy: 0.3819 - val_loss: 1.6061 - val_accuracy: 0.3710\n",
            "Epoch 3/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 1.5267 - accuracy: 0.4031\n",
            "Epoch 3: val_accuracy did not improve from 0.37104\n",
            "187/187 [==============================] - 125s 671ms/step - loss: 1.5267 - accuracy: 0.4031 - val_loss: 1.5980 - val_accuracy: 0.3695\n",
            "Epoch 4/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 1.4705 - accuracy: 0.4346\n",
            "Epoch 4: val_accuracy improved from 0.37104 to 0.37406, saving model to best_model.h5\n",
            "187/187 [==============================] - 126s 675ms/step - loss: 1.4705 - accuracy: 0.4346 - val_loss: 1.5937 - val_accuracy: 0.3741\n",
            "Epoch 5/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 1.4189 - accuracy: 0.4609\n",
            "Epoch 5: val_accuracy improved from 0.37406 to 0.41026, saving model to best_model.h5\n",
            "187/187 [==============================] - 130s 694ms/step - loss: 1.4189 - accuracy: 0.4609 - val_loss: 1.5515 - val_accuracy: 0.4103\n",
            "Epoch 6/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 1.3588 - accuracy: 0.4794\n",
            "Epoch 6: val_accuracy did not improve from 0.41026\n",
            "187/187 [==============================] - 128s 685ms/step - loss: 1.3588 - accuracy: 0.4794 - val_loss: 1.5980 - val_accuracy: 0.3952\n",
            "Epoch 7/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 1.3153 - accuracy: 0.5042\n",
            "Epoch 7: val_accuracy improved from 0.41026 to 0.41780, saving model to best_model.h5\n",
            "187/187 [==============================] - 119s 637ms/step - loss: 1.3153 - accuracy: 0.5042 - val_loss: 1.5917 - val_accuracy: 0.4178\n",
            "Epoch 8/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 1.2623 - accuracy: 0.5283\n",
            "Epoch 8: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 127s 681ms/step - loss: 1.2623 - accuracy: 0.5283 - val_loss: 1.6108 - val_accuracy: 0.3967\n",
            "Epoch 9/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 1.1932 - accuracy: 0.5602\n",
            "Epoch 9: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 128s 685ms/step - loss: 1.1932 - accuracy: 0.5602 - val_loss: 1.6437 - val_accuracy: 0.3861\n",
            "Epoch 10/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 1.1375 - accuracy: 0.5787\n",
            "Epoch 10: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 129s 687ms/step - loss: 1.1375 - accuracy: 0.5787 - val_loss: 1.6211 - val_accuracy: 0.4042\n",
            "Epoch 11/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 1.0772 - accuracy: 0.6028\n",
            "Epoch 11: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 129s 690ms/step - loss: 1.0772 - accuracy: 0.6028 - val_loss: 1.6963 - val_accuracy: 0.3891\n",
            "Epoch 12/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 1.0138 - accuracy: 0.6389\n",
            "Epoch 12: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 120s 644ms/step - loss: 1.0138 - accuracy: 0.6389 - val_loss: 1.6778 - val_accuracy: 0.3952\n",
            "Epoch 13/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 0.9437 - accuracy: 0.6652\n",
            "Epoch 13: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 128s 687ms/step - loss: 0.9437 - accuracy: 0.6652 - val_loss: 1.7007 - val_accuracy: 0.3725\n",
            "Epoch 14/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 0.8847 - accuracy: 0.6929\n",
            "Epoch 14: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 119s 639ms/step - loss: 0.8847 - accuracy: 0.6929 - val_loss: 1.8216 - val_accuracy: 0.3831\n",
            "Epoch 15/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 0.8338 - accuracy: 0.7194\n",
            "Epoch 15: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 120s 641ms/step - loss: 0.8338 - accuracy: 0.7194 - val_loss: 1.7832 - val_accuracy: 0.3816\n",
            "Epoch 16/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 0.7666 - accuracy: 0.7435\n",
            "Epoch 16: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 129s 689ms/step - loss: 0.7666 - accuracy: 0.7435 - val_loss: 1.8054 - val_accuracy: 0.3816\n",
            "Epoch 17/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 0.7097 - accuracy: 0.7652\n",
            "Epoch 17: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 120s 642ms/step - loss: 0.7097 - accuracy: 0.7652 - val_loss: 1.8211 - val_accuracy: 0.3891\n",
            "Epoch 18/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 0.6500 - accuracy: 0.7924\n",
            "Epoch 18: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 129s 692ms/step - loss: 0.6500 - accuracy: 0.7924 - val_loss: 1.8750 - val_accuracy: 0.3725\n",
            "Epoch 19/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 0.6012 - accuracy: 0.8121\n",
            "Epoch 19: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 121s 645ms/step - loss: 0.6012 - accuracy: 0.8121 - val_loss: 1.9226 - val_accuracy: 0.3786\n",
            "Epoch 20/20\n",
            "187/187 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.8269\n",
            "Epoch 20: val_accuracy did not improve from 0.41780\n",
            "187/187 [==============================] - 122s 652ms/step - loss: 0.5588 - accuracy: 0.8269 - val_loss: 1.9306 - val_accuracy: 0.3937\n",
            "21/21 [==============================] - 12s 587ms/step - loss: 1.9306 - accuracy: 0.3937\n",
            "Test Accuracy: 0.3936651647090912\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Load the FER2013 dataset from CSV\n",
        "data = pd.read_csv('fer2013.csv')\n",
        "\n",
        "# Initialize lists to store valid data\n",
        "valid_pixels = []\n",
        "valid_emotions = []\n",
        "\n",
        "# Iterate over the rows of the DataFrame\n",
        "for index, row in data.iterrows():\n",
        "    # Try to convert the pixel string to an array\n",
        "    try:\n",
        "        pixels = np.fromstring(row['pixels'], dtype=int, sep=' ')\n",
        "        # Check if the length matches the expected size (48*48 = 2304)\n",
        "        if len(pixels) == 2304:\n",
        "            valid_pixels.append(pixels)\n",
        "            valid_emotions.append(row['emotion'])\n",
        "    except Exception as e:\n",
        "        # Skip the row if there's an error\n",
        "        print(f\"Error processing row {index}: {e}\")\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "pixels = np.array(valid_pixels)\n",
        "emotions = pd.get_dummies(valid_emotions).values\n",
        "\n",
        "# Normalize pixel values\n",
        "pixels = pixels / 255.0\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(pixels, emotions, test_size=0.1, random_state=42)\n",
        "\n",
        "# Reshape the flattened pixel arrays to images\n",
        "X_train_images = X_train.reshape(-1, 48, 48, 1)\n",
        "X_test_images = X_test.reshape(-1, 48, 48, 1)\n",
        "\n",
        "# Expand the dimensions to match the input shape of VGG16\n",
        "X_train_images = np.repeat(X_train_images, 3, axis=-1)\n",
        "X_test_images = np.repeat(X_test_images, 3, axis=-1)\n",
        "\n",
        "\n",
        "# Load pre-trained VGG16 model without the top (fully connected) layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
        "\n",
        "# Freeze the convolutional base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add new classification layers\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(7, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(base_model.input, x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define a checkpoint callback to save the best model\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "# Train the model with the reshaped input data\n",
        "model.fit(X_train_images, y_train, batch_size=32, epochs=20, validation_data=(X_test_images, y_test), callbacks=[checkpoint])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_images, y_test)\n",
        "print('Test Accuracy:', accuracy)\n",
        "\n"
      ]
    }
  ]
}