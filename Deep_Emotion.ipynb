{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QUQE6PyYIzJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "S4UfGW4jYuxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc07516-c06f-4c7f-918c-17d243c0bb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYBnpgHRYtNc"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/FaceRecognition/fer2013.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A1n3fWXYtJ6"
      },
      "outputs": [],
      "source": [
        "# Extract pixel values and emotions\n",
        "pixels = data['pixels'].apply(lambda x: np.array(x.split(), dtype=int))\n",
        "emotions = data['emotion']\n",
        "usage = data['Usage']  # Assuming there's a column named 'Usage'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0zK9QbmbfO5",
        "outputId": "618b0205-2900-4631-eb23-7a7fae4478e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2304,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "pixels[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5C85TgdbfZ4",
        "outputId": "f9fa84eb-5709-4c10-da8c-5620e21eb4d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35887,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "pixels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgGfME4BYtF3"
      },
      "outputs": [],
      "source": [
        "# Reshape the pixel arrays to 2D arrays\n",
        "pixels_2d = pixels.apply(lambda x: np.reshape(x, (48, 48)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEcv2dG0Ysv8"
      },
      "outputs": [],
      "source": [
        "# Reshape pixel values to be suitable for input to models\n",
        "X = np.array(pixels_2d.tolist()) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIkyxhHIY7Gw"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets based on the 'Usage' column\n",
        "X_train = X[usage == 'Training']\n",
        "y_train = emotions[usage == 'Training']\n",
        "\n",
        "X_test = X[usage == 'PrivateTest']\n",
        "y_test = emotions[usage == 'PrivateTest']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoMMB88qY7DJ",
        "outputId": "2b31d4d6-551c-461f-f5c0-55e3856dc414"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3589, 48, 48)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-MyHuONY7Af",
        "outputId": "520a672c-b71e-46ff-9d83-3445acc752f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.66666667, 0.4627451 , 0.39607843, ..., 0.43921569, 0.51372549,\n",
              "        0.48627451],\n",
              "       [0.65882353, 0.49019608, 0.42352941, ..., 0.43529412, 0.48627451,\n",
              "        0.52156863],\n",
              "       [0.67843137, 0.5254902 , 0.44313725, ..., 0.40392157, 0.44705882,\n",
              "        0.50196078],\n",
              "       ...,\n",
              "       [0.32156863, 0.41568627, 0.38823529, ..., 0.64313725, 0.51764706,\n",
              "        0.49803922],\n",
              "       [0.37647059, 0.41176471, 0.38431373, ..., 0.63529412, 0.50980392,\n",
              "        0.51764706],\n",
              "       [0.40784314, 0.40392157, 0.38823529, ..., 0.62352941, 0.52156863,\n",
              "        0.51372549]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aku6FMcNY65y"
      },
      "outputs": [],
      "source": [
        "X_train_tensor=torch.tensor(X_train,dtype=torch.float)\n",
        "X_test_tensor=torch.tensor(X_test,dtype=torch.float)\n",
        "\n",
        "y_train_tensor=torch.tensor(y_train.values,dtype=torch.long)\n",
        "y_test_tensor=torch.tensor(y_test.values,dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH7f_mmCZHtX"
      },
      "outputs": [],
      "source": [
        "class Deep_Emotion(nn.Module):\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Deep_Emotion class contains the network architecture.\n",
        "        '''\n",
        "        super(Deep_Emotion,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,10,3)\n",
        "        self.conv2 = nn.Conv2d(10,10,3)\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(10,10,3)\n",
        "        self.conv4 = nn.Conv2d(10,10,3)\n",
        "        self.pool4 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.norm = nn.BatchNorm2d(10)\n",
        "\n",
        "        self.fc1 = nn.Linear(810,50)\n",
        "        self.fc2 = nn.Linear(50,7)\n",
        "\n",
        "        self.localization = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, kernel_size=7),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(8, 10, kernel_size=5),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        self.fc_loc = nn.Sequential(\n",
        "            nn.Linear(640, 32),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(32, 3 * 2)\n",
        "        )\n",
        "        self.fc_loc[2].weight.data.zero_()\n",
        "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
        "\n",
        "    def stn(self, x):\n",
        "        xs = self.localization(x)\n",
        "        xs = xs.view(-1, 640)\n",
        "        theta = self.fc_loc(xs)\n",
        "        theta = theta.view(-1, 2, 3)\n",
        "\n",
        "        grid = F.affine_grid(theta, x.size())\n",
        "        x = F.grid_sample(x, grid)\n",
        "        return x\n",
        "\n",
        "    def forward(self,input):\n",
        "        out = self.stn(input)\n",
        "\n",
        "        out = F.relu(self.conv1(out))\n",
        "        out = self.conv2(out)\n",
        "        out = F.relu(self.pool2(out))\n",
        "\n",
        "        out = F.relu(self.conv3(out))\n",
        "        out = self.norm(self.conv4(out))\n",
        "        out = F.relu(self.pool4(out))\n",
        "\n",
        "        out = F.dropout(out)\n",
        "        out = out.view(-1, 810)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mtzn0k7_ZNne",
        "outputId": "07820bb1-c8e3-4c16-d684-a41aec45d5a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Train Loss: 1.7355, Train Acc: 0.3003\n",
            "Epoch [2/100], Train Loss: 1.6429, Train Acc: 0.3528\n",
            "Epoch [3/100], Train Loss: 1.6052, Train Acc: 0.3721\n",
            "Epoch [4/100], Train Loss: 1.5800, Train Acc: 0.3844\n",
            "Epoch [5/100], Train Loss: 1.5630, Train Acc: 0.3908\n",
            "Epoch [6/100], Train Loss: 1.5384, Train Acc: 0.4017\n",
            "Epoch [7/100], Train Loss: 1.5232, Train Acc: 0.4062\n",
            "Epoch [8/100], Train Loss: 1.5098, Train Acc: 0.4133\n",
            "Epoch [9/100], Train Loss: 1.5026, Train Acc: 0.4159\n",
            "Epoch [10/100], Train Loss: 1.4882, Train Acc: 0.4235\n",
            "Epoch [11/100], Train Loss: 1.4883, Train Acc: 0.4225\n",
            "Epoch [12/100], Train Loss: 1.4752, Train Acc: 0.4293\n",
            "Epoch [13/100], Train Loss: 1.4726, Train Acc: 0.4308\n",
            "Epoch [14/100], Train Loss: 1.4625, Train Acc: 0.4366\n",
            "Epoch [15/100], Train Loss: 1.4560, Train Acc: 0.4399\n",
            "Epoch [16/100], Train Loss: 1.4634, Train Acc: 0.4348\n",
            "Epoch [17/100], Train Loss: 1.4488, Train Acc: 0.4407\n",
            "Epoch [18/100], Train Loss: 1.4503, Train Acc: 0.4413\n",
            "Epoch [19/100], Train Loss: 1.4437, Train Acc: 0.4466\n",
            "Epoch [20/100], Train Loss: 1.4426, Train Acc: 0.4490\n",
            "Epoch [21/100], Train Loss: 1.4157, Train Acc: 0.4555\n",
            "Epoch [22/100], Train Loss: 1.4082, Train Acc: 0.4600\n",
            "Epoch [23/100], Train Loss: 1.4047, Train Acc: 0.4568\n",
            "Epoch [24/100], Train Loss: 1.4033, Train Acc: 0.4604\n",
            "Epoch [25/100], Train Loss: 1.3996, Train Acc: 0.4642\n",
            "Epoch [26/100], Train Loss: 1.3997, Train Acc: 0.4625\n",
            "Epoch [27/100], Train Loss: 1.3957, Train Acc: 0.4640\n",
            "Epoch [28/100], Train Loss: 1.3945, Train Acc: 0.4636\n",
            "Epoch [29/100], Train Loss: 1.3953, Train Acc: 0.4664\n",
            "Epoch [30/100], Train Loss: 1.3889, Train Acc: 0.4680\n",
            "Epoch [31/100], Train Loss: 1.3872, Train Acc: 0.4664\n",
            "Epoch [32/100], Train Loss: 1.3865, Train Acc: 0.4709\n",
            "Epoch [33/100], Train Loss: 1.3858, Train Acc: 0.4684\n",
            "Epoch [34/100], Train Loss: 1.3856, Train Acc: 0.4702\n",
            "Epoch [35/100], Train Loss: 1.3824, Train Acc: 0.4689\n",
            "Epoch [36/100], Train Loss: 1.3801, Train Acc: 0.4726\n",
            "Epoch [37/100], Train Loss: 1.3827, Train Acc: 0.4694\n",
            "Epoch [38/100], Train Loss: 1.3793, Train Acc: 0.4715\n",
            "Epoch [39/100], Train Loss: 1.3759, Train Acc: 0.4719\n",
            "Epoch [40/100], Train Loss: 1.3780, Train Acc: 0.4738\n",
            "Epoch [41/100], Train Loss: 1.3717, Train Acc: 0.4762\n",
            "Epoch [42/100], Train Loss: 1.3726, Train Acc: 0.4748\n",
            "Epoch [43/100], Train Loss: 1.3698, Train Acc: 0.4759\n",
            "Epoch [44/100], Train Loss: 1.3690, Train Acc: 0.4796\n",
            "Epoch [45/100], Train Loss: 1.3709, Train Acc: 0.4741\n",
            "Epoch [46/100], Train Loss: 1.3658, Train Acc: 0.4770\n",
            "Epoch [47/100], Train Loss: 1.3680, Train Acc: 0.4769\n",
            "Epoch [48/100], Train Loss: 1.3641, Train Acc: 0.4796\n",
            "Epoch [49/100], Train Loss: 1.3696, Train Acc: 0.4737\n",
            "Epoch [50/100], Train Loss: 1.3648, Train Acc: 0.4793\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# Define batch size, number of epochs, and learning rate\n",
        "batch_size = 128\n",
        "num_epochs = 100\n",
        "learning_rate = 0.005\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/FaceRecognition/model.pth\"\n",
        "\n",
        "# Create TensorDataset and DataLoader for training and test data\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Instantiate the model\n",
        "model = Deep_Emotion()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Using Adam optimizer\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)  # Reduce learning rate by a factor of 0.1 every 20 epochs\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_corrects = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.unsqueeze(1))  # Add one dimension for the channel\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        train_corrects += torch.sum(preds == labels.data)\n",
        "        total_train += len(labels)\n",
        "\n",
        "    scheduler.step()  # Update the learning rate scheduler\n",
        "\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    epoch_train_loss = train_loss / total_train\n",
        "    epoch_train_acc = train_corrects.double() / total_train\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8XEzMTLa5hYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = Deep_Emotion()\n",
        "\n",
        "# Load the saved model state dictionary\n",
        "model_path = '/content/drive/MyDrive/FaceRecognition/model.pth'  # Update with your actual path\n",
        "model.load_state_dict(torch.load(model_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfik_VoC5hMO",
        "outputId": "8069603f-aa08-4192-baf9-1e009f9b20cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define batch size, number of epochs, and learning rate\n",
        "batch_size = 128\n",
        "num_epochs = 100\n",
        "learning_rate = 0.005\n",
        "\n",
        "save_path=\"/content/drive/MyDrive/FaceRecognition/model.pth\"\n",
        "\n",
        "# Create TensorDataset and DataLoader for training and test data\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "JmJXVj7a5tUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_corrects = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.unsqueeze(1))  # Add one dimension for the channel\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        train_corrects += torch.sum(preds == labels.data)\n",
        "        total_train += len(labels)\n",
        "\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    epoch_train_loss = train_loss / total_train\n",
        "    epoch_train_acc = train_corrects.double() / total_train\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "BO-Jul1h6WZ3",
        "outputId": "d8373036-516a-4c15-bc0b-3cebad45d199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Train Loss: 1.1856, Train Acc: 0.5508\n",
            "Epoch [2/100], Train Loss: 1.1919, Train Acc: 0.5472\n",
            "Epoch [3/100], Train Loss: 1.1821, Train Acc: 0.5552\n",
            "Epoch [4/100], Train Loss: 1.1820, Train Acc: 0.5559\n",
            "Epoch [5/100], Train Loss: 1.1839, Train Acc: 0.5559\n",
            "Epoch [6/100], Train Loss: 1.1815, Train Acc: 0.5532\n",
            "Epoch [7/100], Train Loss: 1.1816, Train Acc: 0.5556\n",
            "Epoch [8/100], Train Loss: 1.1814, Train Acc: 0.5535\n",
            "Epoch [9/100], Train Loss: 1.1763, Train Acc: 0.5570\n",
            "Epoch [10/100], Train Loss: 1.1795, Train Acc: 0.5563\n",
            "Epoch [11/100], Train Loss: 1.1802, Train Acc: 0.5511\n",
            "Epoch [12/100], Train Loss: 1.1751, Train Acc: 0.5564\n",
            "Epoch [13/100], Train Loss: 1.1743, Train Acc: 0.5570\n",
            "Epoch [14/100], Train Loss: 1.1837, Train Acc: 0.5545\n",
            "Epoch [15/100], Train Loss: 1.1772, Train Acc: 0.5554\n",
            "Epoch [16/100], Train Loss: 1.1771, Train Acc: 0.5548\n",
            "Epoch [17/100], Train Loss: 1.1754, Train Acc: 0.5563\n",
            "Epoch [18/100], Train Loss: 1.1726, Train Acc: 0.5588\n",
            "Epoch [19/100], Train Loss: 1.1763, Train Acc: 0.5560\n",
            "Epoch [20/100], Train Loss: 1.1751, Train Acc: 0.5577\n",
            "Epoch [21/100], Train Loss: 1.1735, Train Acc: 0.5564\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-8c07ea7a8c01>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add one dimension for the channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBndeBdKiV1-"
      },
      "outputs": [],
      "source": [
        "save_path=\"/content/drive/MyDrive/FaceRecognition/model.pth\"\n",
        "torch.save(model.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeIG89v4ZNj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae02c7d-a96d-4e5f-8d3a-f0a6ce4500aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 0.48397882418500976\n"
          ]
        }
      ],
      "source": [
        "# Evaluation loop\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs.unsqueeze(1))  # Add one dimension for the channel\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy on test set: {accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}